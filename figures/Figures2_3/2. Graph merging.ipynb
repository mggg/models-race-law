{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import geopandas as gpd\n",
    "from gerrychain import Graph\n",
    "from fiona.errors import DriverError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "chen_all_states = 'CA  FL  NJ  NY'.split()  #'AR  AZ  CA  DE  FL  GA  IL  LA  MD  MS  NC  NM  NV  NY  SC  TN  TX  VA  NJ'.split()\n",
    "chen_ei_states = 'AL  AZ  DE  GA  LA  MS  NM  NY  TN  VA AR  CA  FL  IL  MD  NC  NV  SC  TX'.split()\n",
    "\n",
    "# Chen's data is not included in this repository due to its size.\n",
    "# Data is available from http://www-personal.umich.edu/~jowei/race/\n",
    "# (sections 3 and 4)\n",
    "chen_votes_root = '/Users/pjrule/data/chen-data/votes'\n",
    "chen_ei_root = '/Users/pjrule/data/chen-data/ei'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We ultimately did not use Chen's EI and vote data for our experiments in Figures 2 and 3.\n",
    "chen_data_enabled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "chen_columns = {\n",
    "    'BRvotes': 'black_repub',\n",
    "    'BDvotes': 'black_dem',\n",
    "    'HRvotes': 'hispanic_repub',\n",
    "    'HDvotes': 'hispanic_dem',\n",
    "    'ORvotes': 'other_repub',\n",
    "    'ODvotes': 'other_dem'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_nodes = {\n",
    "    'FL': set(['120879801001']), # island (pop. 20)\n",
    "    'NY': set(['360610001001'])  # island (pop. 2)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "levels = ('CD', 'SD', 'HD')\n",
    "suffixes = {\n",
    "    'CD': 'CD',\n",
    "    'SD': 'CD_SD',\n",
    "    'HD': 'CD_SD_HD'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_hd_states = ['NY', 'CA', 'FL']  # use alternate seed plans for HD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CA\n",
      "Loading auxiliary graph...\n",
      "FL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjrule/Dropbox/MGGG/GerryChain/gerrychain/graph/graph.py:239: UserWarning: Found islands (degree-0 nodes). Indices of islands: {914}\n",
      "  \"Found islands (degree-0 nodes). Indices of islands: {}\".format(islands)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading auxiliary graph...\n",
      "removing [914]\n",
      "NJ\n",
      "NY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjrule/Dropbox/MGGG/GerryChain/gerrychain/graph/graph.py:239: UserWarning: Found islands (degree-0 nodes). Indices of islands: {3053}\n",
      "  \"Found islands (degree-0 nodes). Indices of islands: {}\".format(islands)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading auxiliary graph...\n",
      "removing [3053]\n"
     ]
    }
   ],
   "source": [
    "for state in chen_all_states:\n",
    "    print(state)\n",
    "    for level in levels:\n",
    "        try:\n",
    "            state_graph = Graph.from_json(\n",
    "                os.path.join('Seeding-Division-Splits',\n",
    "                             'Output',\n",
    "                             f'{level}_seed',\n",
    "                             f'{state}.json')\n",
    "            )\n",
    "            suffix = suffixes[level]\n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "            \n",
    "    if state in extra_hd_states:\n",
    "        print('Loading auxiliary graph...')\n",
    "        suffix = suffixes['HD']\n",
    "        state_hd_graph = Graph.from_json(\n",
    "            os.path.join('Seeding-Division-Splits',\n",
    "                         'Output',\n",
    "                         'extra',\n",
    "                         f'{state}.json')\n",
    "        )\n",
    "        # Join HD column with existing state graph.\n",
    "        geoid_to_hd = {}\n",
    "        for node in state_hd_graph.nodes:\n",
    "            hd_assignment = state_hd_graph.nodes[node]['SEED_STATE_HOUSE']\n",
    "            geoid_to_hd[state_hd_graph.nodes[node]['GEOID10']] = hd_assignment\n",
    "        for node in state_graph.nodes:\n",
    "            hd_assignment = geoid_to_hd[state_graph.nodes[node]['GEOID10']]\n",
    "            state_graph.nodes[node]['SPLITS_SEED_HD'] = hd_assignment\n",
    "        \n",
    "    \n",
    "    nodes_to_remove = []\n",
    "    for node in state_graph.nodes:\n",
    "        if state_graph.nodes[node]['GEOID10'] in remove_nodes.get(state, set()):\n",
    "            nodes_to_remove.append(node)\n",
    "    state_graph.remove_nodes_from(nodes_to_remove)\n",
    "    if nodes_to_remove:\n",
    "        print('removing', nodes_to_remove)\n",
    "    \n",
    "    nodes_by_geoid = {\n",
    "        state_graph.nodes[n]['GEOID10']: state_graph.nodes[n]\n",
    "        for n in state_graph.nodes\n",
    "    }\n",
    "    graph_bg = set(state_graph.nodes[n]['GEOID10'] for n in state_graph.nodes)\n",
    "    \n",
    "    # Map assignments to range [1, n_districts].\n",
    "    for level in levels:\n",
    "        if level in suffix:\n",
    "            assign_col = f'SPLITS_SEED_{level}'\n",
    "            districts = set()\n",
    "            for node in state_graph.nodes:\n",
    "                districts.add(state_graph.nodes[node][assign_col])\n",
    "            district_map = {\n",
    "                dist: idx + 1\n",
    "                for idx, dist in enumerate(sorted(districts))\n",
    "            }\n",
    "            for node in state_graph.nodes:\n",
    "                curr_assign = state_graph.nodes[node][assign_col]\n",
    "                state_graph.nodes[node][assign_col] = district_map[curr_assign]\n",
    "    \n",
    "    # Add EI data.\n",
    "    if chen_data_enabled and state in chen_ei_states:\n",
    "        try:\n",
    "            chen_df = pd.read_csv(os.path.join(chen_ei_root, f'{state}.txt'), sep='\\t')\n",
    "            chen_df = chen_df.rename(columns=chen_columns)\n",
    "            chen_df = chen_df[['geoid'] + list(chen_columns.values())]\n",
    "            chen_df['bg'] = chen_df['geoid'].astype(str).str.slice(stop=12)\n",
    "            chen_bg_df = chen_df.groupby(by=['bg']).sum().drop(columns=['geoid'])\n",
    "            chen_bg_df = chen_bg_df[~chen_bg_df.index.isin(remove_nodes.get(state, set()))]\n",
    "\n",
    "            chen_bg = set(chen_bg_df.index)\n",
    "            assert not chen_bg - graph_bg\n",
    "            assert sum(nodes_by_geoid[geoid]['TOTPOP'] for geoid in graph_bg - chen_bg) == 0\n",
    "\n",
    "            for bg, row in chen_bg_df.iterrows():\n",
    "                for k, v in row.items():\n",
    "                    nodes_by_geoid[bg][f'chen_{k}'] = v\n",
    "            for bg in graph_bg - chen_bg:\n",
    "                for col in list(chen_columns.values()):\n",
    "                    nodes_by_geoid[bg][f'chen_{col}'] = 0\n",
    "            suffix += '_ei'\n",
    "        except AssertionError:\n",
    "            print(\"Couldn't join EI data.\")\n",
    "        \n",
    "    # Add Obama/Romney vote data.\n",
    "    if chen_data_enabled:\n",
    "      try:\n",
    "          votes_df = gpd.read_file(os.path.join(chen_votes_root, f'{state}.dbf'))\n",
    "          if 'Obama' in votes_df.columns and 'Romney' in votes_df.columns:\n",
    "              votes_df = votes_df[['block', 'Obama', 'Romney']]\n",
    "              votes_df['bg'] = votes_df['block'].astype(str).str.slice(stop=12)\n",
    "              votes_df = votes_df.groupby(by=['bg']).sum()\n",
    "              votes_df = votes_df[~votes_df.index.isin(remove_nodes.get(state, set()))]\n",
    "\n",
    "              votes_bg = set(votes_df.index)\n",
    "              print('votes_bg', len(votes_bg))\n",
    "              print('graph_bg', len(graph_bg))\n",
    "              print('votes_bg - graph_bg', len(votes_bg - graph_bg))\n",
    "              print('graph_bg - votes_bg', len(graph_bg - votes_bg))\n",
    "              assert not votes_bg - graph_bg\n",
    "              assert sum(nodes_by_geoid[geoid]['TOTPOP'] for geoid in graph_bg - votes_bg) == 0\n",
    "\n",
    "              for bg, row in votes_df.iterrows():\n",
    "                  for k, v in row.items():\n",
    "                      nodes_by_geoid[bg][k] = v\n",
    "              for bg in graph_bg - votes_bg:\n",
    "                  for col in ('Obama', 'Romney'):\n",
    "                      nodes_by_geoid[bg][col] = 0     \n",
    "              suffix += '_votes'\n",
    "      except DriverError:\n",
    "          print('Vote data not found. Skipping...')\n",
    "    \n",
    "    state_graph = nx.relabel_nodes(\n",
    "        state_graph,\n",
    "        {n: idx for idx, n in enumerate(state_graph.nodes)}\n",
    "    )\n",
    "    state_graph.to_json(os.path.join('Seeding-Division-Splits', 'processed', f'{state}_{suffix}.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
