{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import networkx as nx\n",
    "from gerrychain.random import random\n",
    "import csv\n",
    "import os\n",
    "from functools import partial\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "from gerrychain import (\n",
    "    Election,\n",
    "    Graph,\n",
    "    MarkovChain,\n",
    "    Partition,\n",
    "    accept,\n",
    "    constraints,\n",
    "    updaters,\n",
    ")\n",
    "from gerrychain.metrics import efficiency_gap, mean_median\n",
    "from gerrychain.proposals import recom\n",
    "from gerrychain.updaters import cut_edges, Tally\n",
    "from gerrychain.tree import PopulatedGraph, contract_leaves_until_balanced_or_none, recursive_tree_part, predecessors, bipartition_tree\n",
    "from networkx.algorithms import tree\n",
    "from collections import deque, namedtuple\n",
    "from state_dictionaries import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import wraps\n",
    "import errno\n",
    "import os\n",
    "import signal\n",
    "\n",
    "class TimeoutError(Exception):\n",
    "    pass\n",
    "\n",
    "def timeout(seconds=10, error_message=os.strerror(errno.ETIME)):\n",
    "    def decorator(func):\n",
    "        def _handle_timeout(signum, frame):\n",
    "            raise TimeoutError(error_message)\n",
    "\n",
    "        def wrapper(*args, **kwargs):\n",
    "            signal.signal(signal.SIGALRM, _handle_timeout)\n",
    "            signal.alarm(seconds)\n",
    "            try:\n",
    "                result = func(*args, **kwargs)\n",
    "            finally:\n",
    "                signal.alarm(0)\n",
    "            return result\n",
    "\n",
    "        return wraps(func)(wrapper)\n",
    "\n",
    "    return decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_check_counties = True\n",
    "\n",
    "def division_random_spanning_tree(graph, division_col=\"COUNTYFP10\", low_weight = 1, high_weight = 10):\n",
    "    for edge in graph.edges:\n",
    "        if graph.nodes[edge[0]][division_col] == graph.nodes[edge[1]][division_col]:\n",
    "            graph.edges[edge][\"weight\"] = low_weight + random.random()\n",
    "        else:\n",
    "            graph.edges[edge][\"weight\"] = high_weight + random.random()\n",
    "    spanning_tree = tree.minimum_spanning_tree(\n",
    "        graph, algorithm=\"kruskal\", weight=\"weight\"\n",
    "    )\n",
    "    return spanning_tree\n",
    "\n",
    "def split_tree_at_division(h, choice=random.choice, division_col=\"COUNTYFP10\"):\n",
    "    root = choice([x for x in h if h.degree(x) > 1])\n",
    "    # BFS predecessors for iteratively contracting leaves\n",
    "    pred = predecessors(h.graph, root)\n",
    "\n",
    "    leaves = deque(x for x in h if h.degree(x) == 1)\n",
    "    while len(leaves) > 0:\n",
    "        leaf = leaves.popleft()\n",
    "        parent = pred[leaf]\n",
    "        if h.graph.nodes[parent][division_col] != h.graph.nodes[leaf][division_col] and h.has_ideal_population(leaf):\n",
    "            return h.subsets[leaf]\n",
    "        # Contract the leaf:\n",
    "        h.contract_node(leaf, parent)\n",
    "        if h.degree(parent) == 1 and parent != root:\n",
    "            leaves.append(parent)\n",
    "    return None\n",
    "\n",
    "\n",
    "def division_bipartition_tree(\n",
    "    graph,\n",
    "    pop_col,\n",
    "    pop_target,\n",
    "    epsilon,\n",
    "    division_col=\"COUNTYFP10\",\n",
    "    node_repeats=1,\n",
    "    spanning_tree=None,\n",
    "    choice=random.choice,\n",
    "    attempts_before_giveup = 100):\n",
    "\n",
    "    populations = {node: graph.nodes[node][pop_col] for node in graph}\n",
    "\n",
    "    balanced_subtree = None\n",
    "    if spanning_tree is None:\n",
    "        spanning_tree = division_random_spanning_tree(graph, division_col=division_col)\n",
    "    restarts = 0\n",
    "    counter = 0\n",
    "    while balanced_subtree is None and counter < attempts_before_giveup:\n",
    "        # print(counter)\n",
    "        if restarts == node_repeats:\n",
    "            spanning_tree = division_random_spanning_tree(graph, division_col=division_col)\n",
    "            restarts = 0\n",
    "            counter +=1\n",
    "        h = PopulatedGraph(spanning_tree, populations, pop_target, epsilon)\n",
    "        if first_check_counties and restarts == 0:\n",
    "            balanced_subtree = split_tree_at_division(h, choice=choice, division_col=division_col)\n",
    "        if balanced_subtree is None:\n",
    "            h = PopulatedGraph(spanning_tree, populations, pop_target, epsilon)\n",
    "            balanced_subtree = contract_leaves_until_balanced_or_none(h, choice=choice)\n",
    "        restarts += 1\n",
    "\n",
    "    if counter >= attempts_before_giveup:\n",
    "        return set()\n",
    "    return balanced_subtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_splits(partition, unit_df, geo_id ='GEOID10', division_col = \"COUNTYFP10\"):\n",
    "    ### since nodes aren't labeled by geo_id\n",
    "    idToAss = {}\n",
    "    partitionDict = dict(partition.assignment)\n",
    "    for i in range(len(unit_df)):\n",
    "        ID = unit_df[geo_id][i]\n",
    "        idx = unit_df.index[unit_df[geo_id] == ID].tolist()[0]\n",
    "        idToAss[ID] = partitionDict[idx]\n",
    "    unit_df[\"current\"] = unit_df[geo_id].map(idToAss)\n",
    "    ###\n",
    "\n",
    "    splits = sum(unit_df.groupby(division_col)[\"current\"].nunique() > 1)\n",
    "    return splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addPartitionToJSON(graph, partition, state, level, keyname):\n",
    "    fileName = \"./Seeding-Division-Splits/Output/\" + level + \"_seed/\" + state + \".json\"\n",
    "    assignment = partition.assignment\n",
    "    ordered_assignment = [assignment[i] for i in range(len(graph.nodes))]\n",
    "    assign_df = pd.DataFrame({keyname: ordered_assignment})\n",
    "    graph.add_data(assign_df)\n",
    "    graph.to_json(fileName)\n",
    "    node_data = dict(graph.nodes.data())\n",
    "    for i in range(len(graph.nodes)):\n",
    "        assert ordered_assignment[i] == node_data[i][keyname]\n",
    "    print(\"Done writing to\", fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @timeout(180)\n",
    "def generate_good_seed_plan(state, level, keyname):\n",
    "    graph_path = \"./Seeding-Division-Splits/Output/HD_seed/\" + state + \".json\"\n",
    "    \n",
    "    graph = Graph.from_json(graph_path)\n",
    "    with open(graph_path) as json_data:\n",
    "        data = json.load(json_data)\n",
    "    unit_df = pd.DataFrame(data['nodes'])\n",
    "    pop_col = \"TOTPOP\"\n",
    "    \n",
    "    if level == \"CD\":\n",
    "        ep = 0.01\n",
    "        k = cd_dict[state]\n",
    "        ass_col = \"SPLITS_SEED_\" + level\n",
    "        threshold = splitsDict[state][0]\n",
    "        burn = 10*k\n",
    "    elif level == \"SD\":\n",
    "        ep = 0.05\n",
    "        k = senate_dict[state]\n",
    "        ass_col = \"SPLITS_SEED_\" + level\n",
    "        threshold = splitsDict[state][1]\n",
    "        burn = 15*k\n",
    "    elif level == \"HD\":\n",
    "        ep = 0.05\n",
    "        k = house_dict[state]\n",
    "        ass_col = \"SPLITS_SEED_\" + level\n",
    "        threshold = splitsDict[state][2]\n",
    "        burn = 10*k\n",
    "    else:\n",
    "        print(\"error.\")\n",
    "        return\n",
    "    \n",
    "    unit_col = \"GEOID10\" #  change if not GEOID10\n",
    "    division_col = \"COUNTYFP10\" #  change if not COUNTYFP10\n",
    "    n_divisions = splitsDict[state][3]\n",
    "    \n",
    "    updaters = {\n",
    "        \"population\": Tally(pop_col, alias=\"population\")\n",
    "    }\n",
    "    \n",
    "    if ass_col == -1:\n",
    "        print(\"Running 'recursive_tree_part'...\")\n",
    "        try:\n",
    "            cddict = recursive_tree_part(graph,\n",
    "                                         range(k),\n",
    "                                         unit_df[pop_col].sum()/k,\n",
    "                                         pop_col,\n",
    "                                         ep,\n",
    "                                         node_repeats=1)\n",
    "            print(\"Ran 'recursive_tree_part'!\")\n",
    "            initial_partition = Partition(graph, cddict, updaters=updaters)\n",
    "            \n",
    "            ideal_population = sum(initial_partition[\"population\"].values()) / len(initial_partition)\n",
    "            division_proposal = partial(recom,\n",
    "                                        pop_col=pop_col,\n",
    "                                        pop_target=ideal_population,\n",
    "                                        epsilon=ep,  \n",
    "                                        method=partial(division_bipartition_tree, \n",
    "                                                                    division_col = division_col), \n",
    "                                                                    node_repeats=2)\n",
    "\n",
    "            chain = MarkovChain(proposal=division_proposal,\n",
    "                                constraints=[constraints.within_percent_of_ideal_population(initial_partition, ep),],\n",
    "                                accept=accept.always_accept,\n",
    "                                initial_state=initial_partition,\n",
    "                                total_steps=burn+5)\n",
    "        except ValueError:\n",
    "            print(\"Take 2: recursive_tree_part...\")\n",
    "            try:\n",
    "                cddict = recursive_tree_part(graph,\n",
    "                                         range(k),\n",
    "                                         unit_df[pop_col].sum()/k,\n",
    "                                         pop_col,\n",
    "                                         ep,\n",
    "                                         node_repeats=1)\n",
    "                initial_partition = Partition(graph, cddict, updaters=updaters)\n",
    "\n",
    "                ideal_population = sum(initial_partition[\"population\"].values()) / len(initial_partition)\n",
    "                division_proposal = partial(recom,\n",
    "                                            pop_col=pop_col,\n",
    "                                            pop_target=ideal_population,\n",
    "                                            epsilon=ep,  \n",
    "                                            method=partial(division_bipartition_tree, \n",
    "                                                                        division_col = division_col), \n",
    "                                                                        node_repeats=2)\n",
    "\n",
    "                chain = MarkovChain(proposal=division_proposal,\n",
    "                                    constraints=[constraints.within_percent_of_ideal_population(initial_partition, ep),],\n",
    "                                    accept=accept.always_accept,\n",
    "                                    initial_state=initial_partition,\n",
    "                                    total_steps=burn+5)\n",
    "            except ValueError:\n",
    "                print(\"Value Error: the given initial_state is not valid according to is_valid\")\n",
    "                return\n",
    "    else:\n",
    "        initial_partition = Partition(graph, assignment=ass_col, updaters=updaters)\n",
    "        \n",
    "        ideal_population = sum(initial_partition[\"population\"].values()) / len(initial_partition)\n",
    "        division_proposal = partial(recom,\n",
    "                                    pop_col=pop_col,\n",
    "                                    pop_target=ideal_population,\n",
    "                                    epsilon=ep,  method=partial(division_bipartition_tree, \n",
    "                                                                division_col = division_col), \n",
    "                                                                node_repeats=2)\n",
    "\n",
    "        chain = MarkovChain(proposal=division_proposal,\n",
    "                            constraints=[constraints.within_percent_of_ideal_population(initial_partition, ep),],\n",
    "                            accept=accept.always_accept,\n",
    "                            initial_state=initial_partition,\n",
    "                            total_steps=burn+5)\n",
    "\n",
    "    t=0\n",
    "    min_s = 999999\n",
    "    orig_county_splits = num_splits(initial_partition, unit_df, geo_id =unit_col, division_col = division_col)\n",
    "    \n",
    "    print(\"Starting chain, original county splits: %d / %d\" % (orig_county_splits, n_divisions))\n",
    "    print(\"Want to get below \" + str(threshold) + \" county splits [using enacted \" + level + \"s]\")\n",
    "    \n",
    "    if orig_county_splits < threshold or orig_county_splits < 2: # might not be good to have second Bool...\n",
    "        print(\"Success!\")\n",
    "        print(\"Seed plan already respects county splits well.\")\n",
    "        addPartitionToJSON(graph, initial_partition, state, level, keyname)\n",
    "        return orig_county_splits, n_divisions, threshold\n",
    "    print(\"We won't record the first \" + str(burn) + \" tries to get to a low # of splits...\")\n",
    "    begin = datetime.now()\n",
    "    for part in chain:\n",
    "        if t < burn:\n",
    "            t += 1\n",
    "            continue\n",
    "        s = num_splits(part, unit_df, geo_id =unit_col, division_col = division_col)\n",
    "        end = datetime.now()\n",
    "        if s < threshold:\n",
    "            print(\"Success!\")\n",
    "        else:\n",
    "            print(\"Failure\")\n",
    "        print(\"In \", str(end-begin), \"found a partition with county splits = \" + str(s) + \"/\" + str(n_divisions))\n",
    "        if s > orig_county_splits: # only update JSON if you improve on county splits\n",
    "            part = initial_partition\n",
    "        addPartitionToJSON(graph, part, state, level, keyname)\n",
    "        return s, n_divisions, threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_seeds_for(level, states=states_list):\n",
    "    for state in states:\n",
    "        if level == \"CD\" and state == \"DE\":\n",
    "            continue\n",
    "        infoFile_path = \"./Seeding-Division-Splits/Output/\" + level + \"_seed/states.txt\"\n",
    "        begin = datetime.now()\n",
    "        print(\"Generating seed for\", state)\n",
    "        try:\n",
    "            n_s, n_d, thresh = generate_good_seed_plan(state, level, \"SPLITS_SEED_\" + level)\n",
    "            infoFile = open(infoFile_path, \"a\")\n",
    "            if n_s >= thresh:\n",
    "                infoFile.writelines(state + \": \" + str(n_s) + \"/\" + str(n_d) + \" (\" + str(thresh) + \") --- splits/counties (enacted splits) --- NOT BETTER THAN ENACTED\\n\")\n",
    "            else:\n",
    "                infoFile.writelines(state + \": \" + str(n_s) + \"/\" + str(n_d) + \" (\" + str(thresh) + \") --- splits/counties (enacted splits)\\n\")\n",
    "            infoFile.close()\n",
    "        except:\n",
    "            print(state + \" raised an error\")\n",
    "            infoFile = open(infoFile_path, \"a\")\n",
    "            infoFile.writelines(state + \": ERROR\\n\")\n",
    "            infoFile.close()\n",
    "        finally:\n",
    "            end = datetime.now()\n",
    "            print(\"Finished\", state, \"in\", str(end-begin))\n",
    "            print(\"-------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating seed for AZ\n",
      "Starting chain, original county splits: 10 / 15\n",
      "Want to get below 10 county splits [using enacted HDs]\n",
      "We won't record the first 600 tries to get to a low # of splits...\n",
      "AZ raised an error\n",
      "Finished AZ in 0:00:18.792292\n",
      "-------\n",
      "Generating seed for NV\n",
      "Starting chain, original county splits: 5 / 17\n",
      "Want to get below 5 county splits [using enacted HDs]\n",
      "We won't record the first 420 tries to get to a low # of splits...\n",
      "NV raised an error\n",
      "Finished NV in 0:00:00.972586\n",
      "-------\n",
      "Generating seed for NJ\n",
      "NJ raised an error\n",
      "Finished NJ in 0:00:04.356765\n",
      "-------\n",
      "Generating seed for NC\n",
      "NC raised an error\n",
      "Finished NC in 0:00:00.243951\n",
      "-------\n",
      "Generating seed for TN\n",
      "TN raised an error\n",
      "Finished TN in 0:00:00.170410\n",
      "-------\n",
      "Generating seed for TX\n",
      "TX raised an error\n",
      "Finished TX in 0:00:00.636239\n",
      "-------\n",
      "CPU times: user 24.2 s, sys: 581 ms, total: 24.8 s\n",
      "Wall time: 25.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "generate_seeds_for(\"HD\", states=[\"AZ\",\"NV\",\"NJ\",\"NC\",\"TN\",\"TX\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
